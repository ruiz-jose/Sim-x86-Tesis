# Arquitectura de computadoras {#arquitectura}
Este capítulo presenta los conceptos fundamentales de la arquitectura de computadoras, abordando las filosofías de diseño CISC y RISC, la evolución de la arquitectura x86 y una introducción al lenguaje ensamblador, temas que sientan las bases para comprender el funcionamiento interno de los sistemas informáticos.

## Introducción a la arquitectura de computadoras
La arquitectura de computadoras se centra en el diseño y la especificación de los componentes visibles para el programador en un sistema informático, como el conjunto de instrucciones, la organización de la memoria y los mecanismos de entrada/salida. Su objetivo principal es optimizar el rendimiento y la eficiencia del sistema. Esta disciplina se extiende desde la interacción entre el hardware y el software hasta la integración de sistemas completos, siendo fundamental para el avance de tecnologías modernas y sostenibles [@hennessy_computer_2012; @stallings_computer_2013].

Comprender la arquitectura de una computadora implica tener un conocimiento profundo de atributos claves como el repertorio de instrucciones (por ejemplo, arquitecturas x86 o ARM), la capacidad de procesamiento (32 o 64 bits), los mecanismos de entrada/salida, las técnicas de direccionamiento de memoria (directo o segmentado) y la gestión de la jerarquía de memoria [@null_essentials_2014]. Además, aspectos como el paralelismo y la eficiencia energética son esenciales para mejorar el rendimiento de los sistemas, así como para optimizar el desarrollo de software y sistemas operativos modernos [@hennessy_computer_2012; @patterson_computer_2014].

Es fundamental distinguir entre la arquitectura de computadoras, que abarca los componentes visibles al programador, y la organización de computadoras, que se enfoca en la implementación física de dicha arquitectura, incluye cómo están dispuestos y coordinados los elementos del hardware, como la memoria, las señales de control y las unidades de procesamiento, para cumplir con los objetivos de rendimiento y funcionalidad [@tanenbaum_structured_2013; @murdocca_principles_2000].

El estudio de la arquitectura de computadoras no solo permite comprender el 
funcionamiento interno de los sistemas informáticos, sino que también facilita 
su adaptación y optimización para satisfacer las demandas de nuevas tendencias 
tecnológicas, como la computación en la nube, la inteligencia artificial y el 
Internet de las cosas. La arquitectura bien diseñada es el cimiento que permite 
a estas tecnologías alcanzar su máximo potencial, impulsando de manera 
significativa la innovación. 
[@hennessy_computer_2012; @stallings_computer_2013]

Una arquitectura bien diseñada es el cimiento sobre el cual se desarrollan tecnologías modernas, permitiendo que alcancen su máximo potencial e impulsen significativamente la innovación.

Tener un conocimiento profundo de la arquitectura y la organización de los sistemas informáticos es vital para cualquier profesional en el campo de la informática. No solo habilita la creación de sistemas más eficientes y escalables, sino que también proporciona una base sólida para explorar áreas emergentes como la seguridad informática y los sistemas embebidos, sectores de creciente relevancia en la industria [@patterson_computer_2014]. El dominio de la arquitectura de computadoras abre un abanico de oportunidades profesionales en áreas emergentes como la seguridad informática y los sistemas embebidos, sectores de creciente relevancia en la industria.

En resumen, el estudio de la arquitectura de computadoras es crucial no solo para entender cómo funcionan internamente los sistemas informáticos y resolver problemas de rendimiento, sino también para diseñar soluciones innovadoras en áreas clave como la inteligencia artificial, la ciberseguridad y los sistemas embebidos. Este conocimiento es esencial para abordar los retos tecnológicos del futuro y acceder a un mercado laboral que valora la capacidad de crear y optimizar sistemas cada vez más poderosos y eficientes [@stallings_computer_2013].

## Arquitecturas Von Neumann y Harvard
Para entender las arquitecturas modernas, es esencial conocer dos modelos históricos que han sentado las bases del diseño actual de sistemas informáticos: Von Neumann y Harvard. Estos paradigmas no solo forman el cimiento de muchas arquitecturas contemporáneas, sino que también ayudan a comprender sus diferencias, ventajas y limitaciones.

### Arquitectura Von Neumann
La arquitectura Von Neumann, propuesta por John von Neumann en 1945, se caracteriza por utilizar un único espacio de memoria para almacenar tanto los datos como las instrucciones, y un único bus para transferir ambos tipos de información. Esta simplicidad ha favorecido su adopción generalizada, pero también trae consigo una limitación importante: el "cuello de botella de Von Neumann". Este fenómeno ocurre cuando el bus único se convierte en un factor restrictivo para la velocidad de procesamiento, especialmente en sistemas que requieren un acceso simultáneo a datos e instrucciones. Aunque esta arquitectura sigue siendo la base de muchas computadoras actuales, se han implementado optimizaciones y mejoras para mitigar sus limitaciones en los sistemas modernos [@hennessy_computer_2012; @stallings_computer_2013].

```{r vonneumann, echo=FALSE, fig.cap="Arquitectura Von Neumann", fig.align = 'center', out.width = "85%"}
knitr::include_graphics(path = "images/vonneumann.png")
```

### Arquitectura Harvard
En contraste, la arquitectura Harvard separa físicamente las memorias de datos y de instrucciones, permitiendo que el procesador acceda a ambas de forma simultánea. Este diseño elimina el cuello de botella de Von Neumann, logrando un rendimiento más eficiente, lo que la convierte en una opción preferida para sistemas que requieren un alto desempeño, como los sistemas embebidos y los procesadores de señal digital (DSP). La arquitectura Harvard es especialmente adecuada para aplicaciones donde el acceso rápido y eficiente a los datos es crucial [@tanenbaum_structured_2013].

```{r harvard, echo=FALSE, fig.cap="Arquitectura Harvard", fig.align = 'center', out.width = "85%"}
knitr::include_graphics(path = "images/harvard.png")
```

### Comparación y aplicaciones modernas
Aunque la simplicidad y flexibilidad de la arquitectura Von Neumann continúan siendo pilares fundamentales para una amplia gama de sistemas, la arquitectura Harvard ha ganado popularidad en escenarios donde la eficiencia y la velocidad son prioritarias, como en dispositivos móviles y sistemas de tiempo real. Hoy en día, arquitecturas modernas como **x86**, **ARM** y **RISC-V** implementan una combinación de ambos modelos para maximizar tanto el rendimiento como la eficiencia energética [@null_essentials_2014].

Esta integración híbrida permite a los diseñadores aprovechar las ventajas de cada enfoque, adaptando los sistemas a las necesidades específicas de las aplicaciones. La dicotomía entre ambas arquitecturas sigue siendo clave en la evolución de los sistemas modernos, donde el rendimiento y la eficiencia son factores críticos para el desarrollo de nuevas tecnologías.

## Tipos de arquitecturas
El análisis de diversas arquitecturas de computadoras es esencial para comprender sus respectivas ventajas y limitaciones en diferentes contextos de aplicación. Esta evaluación comparativa permite a los diseñadores y desarrolladores de sistemas seleccionar la arquitectura más adecuada para sus necesidades, considerando factores clave como la eficiencia energética, la complejidad del hardware y las aplicaciones específicas en las que se utilizará cada una.

### Arquitectura x86
La arquitectura x86, desarrollada inicialmente por Intel, ha dominado el mercado de computadoras de escritorio y servidores durante décadas gracias a su alto rendimiento y amplia compatibilidad con software legado. Su conjunto de instrucciones complejo (ISA) proporciona flexibilidad para una variedad de aplicaciones, aunque a costa de un mayor desafío en el diseño del hardware. Este equilibrio entre compatibilidad y rendimiento hace que x86 sea una opción preferida para entornos donde la capacidad de procesamiento es prioritaria, como en servidores y estaciones de trabajo [@hennessy_computer_2012].

### Arquitectura ARM
Reconocida por su alta eficiencia energética, la arquitectura ARM es la columna vertebral de dispositivos móviles y sistemas embebidos. Basada en el paradigma de conjunto de instrucciones reducidas (RISC), ARM simplifica el diseño del hardware y optimiza el consumo energético, características que la convierten en la elección ideal para aplicaciones como smartphones y tablets. Aunque su rendimiento bruto es inferior al de x86, su balance entre eficiencia y capacidad de procesamiento es crucial para mercados donde la autonomía es esencial [@patterson_computer_2014].

### Arquitectura MIPS
MIPS, otra arquitectura basada en RISC, ha destacado históricamente en sistemas embebidos y entornos educativos debido a su simplicidad y eficacia. Aunque su relevancia ha disminuido frente a opciones como ARM, MIPS sigue siendo valiosa en nichos específicos que requieren un diseño eficiente y de bajo costo. Su conjunto de instrucciones, aunque menos versátil que el de x86, logra un equilibrio adecuado para aplicaciones de mediana complejidad [@hennessy_computer_2012].

### Arquitectura RISC-V
RISC-V ha revolucionado el panorama de la arquitectura de computadoras con su enfoque abierto y libre. Su ISA flexible permite a los desarrolladores personalizar sistemas según necesidades específicas, haciéndola especialmente atractiva para investigación, educación y aplicaciones embebidas. Basada en principios RISC, RISC-V combina eficiencia energética con un diseño de hardware simplificado, y su creciente ecosistema la posiciona como una fuerte competidora frente a arquitecturas establecidas como ARM [@waterman_risc-v_2014].

### Compararativa de arquitecturas
Las características distintivas de cada arquitectura condicionan su idoneidad para diversas aplicaciones. Por ejemplo, mientras x86 sobresale en entornos de alto rendimiento, ARM domina en dispositivos móviles gracias a su eficiencia energética. MIPS y RISC-V, por su parte, se especializan en nichos como sistemas embebidos y proyectos personalizados. La selección adecuada de una arquitectura impacta significativamente en el éxito de un proyecto, desde el diseño hasta su implementación final [@patterson_computer_2014].

```{r tabla-comparacion-cpu, echo=FALSE, message=FALSE, warning=FALSE}
library(knitr)

comparacion_cpu <- data.frame(
  Característica = c(
    "Eficiencia Energética",
    "Complejidad ISA",
    "Rendimiento",
    "Compatibilidad",
    "Áreas de Aplicación"
  ), # nolint: line_length_linter.
  x86 = c("Moderada", "Alta", "Alto", "Alta (hacia atrás)",
          "Escritorio, servidores"),
  ARM = c("Alta", "Baja", "Moderado", "Moderada", "Dispositivos móviles"),
  MIPS = c("Moderada", "Moderada", "Moderado",
           "Moderada", "Sistemas embebidos"),
  `RISC-V` = c("Alta", "Baja", "Variable", "Alta", "Investigación, embebidos")
)

kable(
  comparacion_cpu,
  format = "markdown",
  caption = "Comparación de Arquitecturas"
)
```

## Repertorio de instrucciones
El repertorio de instrucciones, conocido como ISA (Instruction Set Architecture), define el conjunto de operaciones que un procesador puede ejecutar y cómo se codifican dichas operaciones. Este conjunto incluye instrucciones aritméticas, lógicas, de control y manipulación de datos, además de los modos de direccionamiento y los formatos de las instrucciones. El diseño del ISA tiene un impacto directo en el rendimiento, la eficiencia energética y la flexibilidad del procesador, lo que lo convierte en un componente clave en la arquitectura de computadoras [@hennessy_computer_2012; @null_essentials_2014; @stallings_computer_2013].

### Características clave del ISA
Entre las características fundamentales a considerar en el diseño de un repertorio de instrucciones se encuentran las siguientes [@hennessy_computer_2012]:

  - **Tipos de operandos**: representan los datos que las instrucciones pueden manipular, como enteros, números en punto flotante, caracteres y direcciones de memoria. Un ISA eficiente debe soportar una amplia variedad de operandos para maximizar su versatilidad.
  - **Tipos de operaciones**: incluyen las operaciones que el procesador puede realizar, como aritméticas (suma, resta), lógicas (AND, OR), de control (saltos, llamadas a subrutinas) y de manipulación de datos (almacenamiento, carga). Un repertorio bien diseñado debe equilibrar funcionalidad y simplicidad.
  - **Modos de direccionamiento**: determinan cómo se especifican los operandos en las instrucciones. Modos como inmediato, directo, indirecto y relativo ofrecen diferentes niveles de flexibilidad y eficiencia.
  - **Formato de las instrucciones**: define la estructura de una instrucción, incluyendo su longitud, el número de operandos y los modos de direccionamiento. Este aspecto influye tanto en la complejidad del procesador como en su rendimiento.

```{r repInstCaracteristicas, echo=FALSE, fig.cap="Características repertorio de instrucciones", fig.align = 'center', out.width = "100%"}
knitr::include_graphics(path = "images/repInstCaracteristicas.jpg")
```

### Modos de direccionamiento
Los modos de direccionamiento son esenciales para determinar cómo el procesador accede a los datos necesarios para ejecutar una instrucción. Los modos más comunes incluyen [@stallings_computer_2013; @hennessy_computer_2012]:

  a) **Inmediato**: el operando está directamente incluido en la instrucción, permitiendo acceso rápido a valores constantes. Es eficiente para operaciones simples, aunque limitado a operandos pequeños.
  b) **Directo**: la instrucción contiene la dirección de memoria del operando. Es fácil de usar, pero está restringido por el rango de direcciones accesibles.
  c) **Indirecto**: la instrucción apunta a una dirección que contiene la ubicación real del operando, lo que amplía el rango de direcciones a costa de un acceso adicional a memoria.
  d) **Registro**: el operando se encuentra en un registro del procesador, proporcionando acceso extremadamente rápido, pero limitado por la cantidad de registros disponibles.
  e) **Registro Indirecto**: similar al modo indirecto, pero la dirección se almacena en un registro, combinando rapidez y flexibilidad.
  f) **Con Desplazamiento**: combina una dirección base con un valor de desplazamiento, ideal para estructuras como arrays y matrices.
  g) **Pila**: el operando está en la parte superior de la pila, útil para gestionar subrutinas y el paso de parámetros.

Estos modos se ilustran en la figura \@ref(fig:ModDir) según [@stallings_computer_2013]:
```{r ModDir, echo=FALSE, fig.cap="Modos de direccionamiento ", fig.align = 'center', out.width = "80%"}
knitr::include_graphics(path = "images/modosdireccionamiento.png")
```

  - A = contenido de un campo de dirección en la instrucción
  - R = contenido de un campo de dirección en la instrucción que referencia a un registro
  - EA = dirección real (efectiva) de la posición que contiene el operando que se referencia

La tabla \@ref(tab:tab_mod_dir) detalla el cálculo de la dirección para cada modo de direccionamiento.

```{r tab_mod_dir , echo=FALSE, message=FALSE, warning=FALSE}
library(knitr)

# Crear los datos de la tabla
tab_mod_dir <- data.frame(
  `Modo` = c("Inmediato", "Directo", "Indirecto", "Registro",
             "Indirecto con registro", "Con desplazamiento", "Pila"),
  `Algoritmo` = c("Operando \u2190 A", "EA \u2190 A", "EA \u2190 (A)",
                  "EA \u2190 R", "EA \u2190 (R)", "EA \u2190 A + (R)",
                  "EA \u2190 cabecera de la pila"),
  `Principal ventaja` = c("No referencia a memoria",
                          "Es sencillo", "Espacio de direcciones grande",
                          "No referencia a memoria",
                          "Espacio de direcciones grande",
                          "Flexibilidad",
                          "No referencia a memoria"),
  `Principal desventaja` = c(
    "Operando de magnitud limitada",
    "Espacio de direcciones limitado",
    "Referencias múltiples a memoria",
    "Número limitado de registros",
    "Referencia extra a memoria",
    "Complejidad",
    "Aplicabilidad limitada"
  )
)

kable(
  tab_mod_dir,
  format = "markdown",
  caption = "Modos de direccionamiento básicos"
)
```

### Formato de las instrucciones
El formato de las instrucciones define su estructura, incluyendo longitud, cantidad de operandos y campos adicionales como el opcode. Este formato afecta la rapidez de decodificación y la eficiencia general del procesador [@hennessy_computer_2012; @tanenbaum_structured_2013]:

- **Longitud de la instrucción**: puede ser fija o variable. La longitud fija simplifica el diseño del hardware, mientras que la variable optimiza el uso de memoria, aunque incrementa la complejidad de decodificación.
- **Cantidad de operandos**: las instrucciones pueden trabajar con diferentes números de operandos (de 0 a 3 o más). Más operandos ofrecen mayor versatilidad, pero aumentan la complejidad y longitud de las instrucciones.
- **Campos de instrucción**: incluyen el opcode y campos adicionales como operandos, modos de direccionamiento y flags de condición. Estos campos determinan cuántas y qué tipo de operaciones puede ejecutar el procesador en un ciclo de reloj.

La Figura @ref(fig:formatoInst) ilustra un esquema típico de formato de instrucciones:

```{r formatoInst, echo=FALSE, fig.cap="Formato de instrucciones ", fig.align = 'center', out.width = "100%"}
knitr::include_graphics(path = "images/formatoInst.jpg")
```

## Filosofías CISC y RISC
El diseño del repertorio de instrucciones es un componente esencial en la arquitectura de procesadores.  Dos de las filosofías más influyentes en este campo son **CISC (Complex Instruction Set Computing)** y **RISC (Reduced Instruction Set Computing)**. Mientras que **CISC** prioriza la reducción del número de instrucciones necesarias para realizar tareas complejas mediante operaciones multifuncionales, **RISC** simplifica el conjunto de instrucciones con el objetivo de maximizar la velocidad y la eficiencia energética. En esta sección se analizan ambos enfoques y sus implicaciones en el diseño de procesadores [@hennessy_computer_2012; @patterson_computer_2014].

### CISC
Las arquitecturas **CISC**, como la **x86**, se caracterizan por su enfoque en reducir el número de instrucciones requeridas para completar operaciones complejas. Esto se logra mediante la inclusión de instrucciones que combinan múltiples operaciones en un solo ciclo. Como resultado, los programadores necesitan escribir menos líneas de código para alcanzar un objetivo específico.

Sin embargo, este diseño implica ciertas desventajas. La **decodificación** y **ejecución** de instrucciones CISC requiere un hardware considerablemente más complejo, y las instrucciones de longitud variable, típicas de estas arquitecturas, pueden aumentar el tiempo de decodificación. Esto genera cuellos de botella en el pipeline y limita el rendimiento.

Por ejemplo, los procesadores **x86** que ha evolucionado hacia un enfoque híbrido. Utiliza microcódigo para descomponer las instrucciones complejas en operaciones más simples, parecidas a las de un procesador RISC. Aunque esta estrategia mejora la eficiencia de ejecución en algunos casos, el diseño sigue siendo más costoso en términos de consumo energético y complejidad [@patterson_computer_2014].

### RISC {#RISC}
Por su parte, las arquitecturas **RISC**, como **ARM** y **MIPS**, adoptan un conjunto reducido de instrucciones de longitud fija. Esta simplificación facilita la decodificación y permite que muchas instrucciones se ejecuten en un solo ciclo de reloj. Además, esta filosofía favorece la implementación de técnicas avanzadas como el pipelining y la predicción de ramas, optimizando así el rendimiento.

A nivel de hardware, RISC prioriza la eficiencia energética, una característica crucial en dispositivos móviles y sistemas embebidos. Por ello, procesadores como los basados en ARM han dominado estos mercados. La simplicidad y el bajo CPI (ciclos por instrucción) han sido factores determinantes en su adopción [@hennessy_computer_2012].

### Comparativa entre CISC y RISC
Las diferencias entre CISC y RISC son evidentes tanto a nivel de diseño como de implementación. En las arquitecturas RISC, las instrucciones tienen una longitud fija, lo que simplifica la decodificación, reduce la latencia y mejora la predictibilidad del rendimiento. Además, este formato mejora la eficiencia del uso de la memoria caché, al ocupar menos espacio y facilitar accesos más rápidos.

En cambio, las arquitecturas CISC, como x86, emplean instrucciones de longitud variable, lo que les permite ofrecer una mayor flexibilidad y un repertorio más amplio de operaciones. Sin embargo, esta flexibilidad conlleva un mayor tiempo de decodificación y una complejidad adicional en la implementación del pipeline. Esto puede causar problemas como interrupciones en el flujo debido a errores de predicción de ramas, aunque se mitiguen mediante técnicas avanzadas como la predicción dinámica de saltos y el prefetching [@tanenbaum_structured_2013].

Por ejemplo, en RISC, los modos de direccionamiento son simples y permiten un acceso más rápido a los operandos, reduciendo la latencia en el pipeline [@stallings_computer_2013]. En CISC, los modos de direccionamiento más complejos proporcionan flexibilidad a costa de una mayor latencia, lo que afecta el rendimiento general del sistema.

#### Ejemplos de instrucciones
Para ilustrar la diferencia entre ambas filosofías, se presenta el siguiente ejemplo: cargar dos valores de memoria, sumarlos y almacenar el resultado en una dirección de memoria.

RISC:

```{r  code0, results='asis', echo=FALSE}
if (knitr::is_latex_output()) {
  cat("
  \\begin{lstlisting}
  ; Carga el valor inmediato 10 en el registro R0
  LOAD R1, [mem1]    # Cargar el valor de mem1 en el registro R1
  LOAD R2, [mem2]    # Cargar el valor de mem2 en el registro R2
  ADD  R3, R1, R2    # Sumar los valores en los registros R1 y R2, guardar en R3
  STORE R3, [mem1]   # Guardar el resultado en mem1
  \\end{lstlisting}
  ")
} else {
  cat("
  ```assembly
  LOAD R1, [mem1]    # Cargar el valor de mem1 en el registro R1
  LOAD R2, [mem2]    # Cargar el valor de mem2 en el registro R2
  ADD  R3, R1, R2    # Sumar los valores en los registros R1 y R2, guardar en R3
  STORE R3, [mem1]   # Guardar el resultado en mem1
  ```")
}
```

CISC:

```{r code1, results='asis', echo=FALSE}
if (knitr::is_latex_output()) {
  cat("
  \\begin{lstlisting}
  MOV EAX, [mem1]    ; Cargar el valor de mem1 en el registro EAX
  ADD EAX, [mem2]    ; Sumar el valor de mem2 con EAX
  MOV [mem1], EAX    ; Guardar el resultado de la suma de vuelta en mem1
  \\end{lstlisting}
  ")
} else {
cat("
    ```assembly
  MOV EAX, [mem1]    ; Cargar el valor de mem1 en el registro EAX
  ADD EAX, [mem2]    ; Sumar el valor de mem2 con EAX
  MOV [mem1], EAX    ; Guardar el resultado de la suma de vuelta en mem1
    ```
  ")
}

```

La tabla \@ref(tab:ciscrisc) resume las principales diferencias entre estas filosofías.

```{r ciscrisc, echo=FALSE, message=FALSE, warning=FALSE}
library(knitr)
library(kableExtra)

ciscrisc <- data.frame(
Aspecto = c(
"Objetivo principal",
"Tipo de instrucciones",
"Decodificación y ejecución",
"Longitud de instrucciones",
"Eficiencia energética",
"Modos de direccionamiento"
),
CISC = c(
"Minimizar el número de instrucciones para operaciones complejas",
"Instrucciones complejas, longitud variable",
"Requiere hardware más complejo, posibles cuellos de botella en el pipeline",
"Longitud variable, puede aumentar el tiempo de decodificación",
"Menor eficiencia energética en comparación con RISC",
"Flexibilidad a costa de mayor latencia"),
RISC = c(
"Simplificar el conjunto de instrucciones para optimizar velocidad y",
"eficiencia",
"energética",
"Instrucciones simples, longitud fija",
"Decodificación más sencilla, facilita el uso de técnicas avanzadas como",
"pipelining",
"Longitud fija, simplifica la decodificación y mejora la predictibilidad del",
"rendimiento",
"Mayor eficiencia energética, especialmente en dispositivos móviles",
"Acceso más rápido a los operandos, menor latencia")
)

if (knitr::is_latex_output()) {
kable(ciscrisc, format = "latex", booktabs = TRUE,
caption = "Comparativa entre CISC y RISC") %>%
kable_styling(latex_options = "scale_down") %>%
column_spec(1, width = "6cm") %>%
column_spec(2, width = "5cm") %>%
column_spec(3, width = "5cm") %>%
row_spec(1:6, extra_latex_after = "\\addlinespace[10pt]")
} else {
kable(ciscrisc, format = "html",
table.attr = "class='table table-striped'",
caption = "Comparativa entre CISC y RISC") %>%
kable_styling(full_width = FALSE) %>%
column_spec(1, width = "20em") %>%
column_spec(2, width = "15em") %>%
column_spec(3, width = "15em")
}
```

#### Convergencia de filosofías
A pesar de sus diferencias, las arquitecturas modernas tienden a integrar características de ambas filosofías. Por ejemplo, los procesadores x86 adoptan técnicas propias de RISC para mejorar la eficiencia energética y el rendimiento. Esta convergencia refleja cómo los avances en diseño de procesadores buscan combinar lo mejor de cada enfoque, maximizando la flexibilidad y la eficiencia para adaptarse a las necesidades actuales y futuras del mercado.

## Arquitectura x86
La arquitectura x86, ampliamente reconocida por su influencia y uso extendido en computadoras de escritorio y servidores, tuvo sus inicios en 1978 con el procesador Intel 8086, que introdujo una arquitectura de 16 bits. Desde entonces, ha experimentado una evolución continua, marcando hitos significativos en la historia de la computación. En 1985, el Intel 80386 introdujo la arquitectura de 32 bits, habilitando capacidades como la memoria virtual. Posteriormente, en 2003, AMD amplió el estándar con la arquitectura AMD64, llevando x86 a 64 bits, lo que permitió acceder a mayores espacios de memoria y mejorar el rendimiento en aplicaciones intensivas. Estas innovaciones fueron adoptadas por Intel, consolidando la arquitectura x86 como una de las más versátiles y potentes del mercado [@stallings_computer_2013; @intel_64_2016; @amd_developer_2019; @abel_ibm_2000].

### Evolución de la arquitectura x86
Uno de los pilares del éxito de la arquitectura x86 ha sido su retrocompatibilidad, permitiendo la ejecución de aplicaciones de 16, 32 y 64 bits en un mismo sistema. Esta capacidad no solo ha asegurado la continuidad del ecosistema x86, sino que también ha protegido las inversiones en software y sistemas operativos, lo que resulta fundamental en el ámbito empresarial y académico.

A continuación, se presenta la tabla \@ref(tab:hitosx86) que resume los hitos clave en la evolución de los procesadores x86:

```{r hitosx86, echo=FALSE, message=FALSE, warning=FALSE}
library(knitr)

hitosx86 <- data.frame(
Procesador = c("Intel 8086", "Intel 80386", "AMD64"),
`Año de Lanzamiento` = c(1978, 1985, 2003),
`Número de Bits` = c(16, 32, 64),
`Nuevas Características` = c(
"Arquitectura inicial",
"Memoria virtual",
"Extensiones de 64 bits"
)
)

kable(hitosx86, format = "markdown", caption = "Hitos procesadores x86")
```

La tabla \@ref(tab:evolucionx86) muesta comó la evolución de x86 ha estado marcada por avances tecnológicos que han impulsado la informática hacia nuevas fronteras:

```{r evolucionx86, echo=FALSE, message=FALSE, warning=FALSE}
library(knitr)

evolucionx86 <- data.frame(
Año = c(1978, 1982, 1985, 1989, 1993, 1995, 2003, 2006),
Procesador = c("Intel 8086", "Intel 80286", "Intel 80386", "Intel 80486", "Intel Pentium", "Intel Pentium Pro", "AMD64", "Intel Core"), # nolint
`Innovación_Principal`  = c(
"Introducción de la arquitectura x86, 16 bits",
"Modos de operación adicionales",
"Arquitectura de 32 bits, memoria virtual",
"Unidad de punto flotante integrada, mejor caché",
"Ejecución superescalar, predicción de saltos",
"Ejecución fuera de orden, caché L2 integrada",
"Extensiones a 64 bits, mayor acceso a memoria",
"Optimización de rendimiento y eficiencia energética")
)

kable(
evolucionx86,
format = "markdown",
caption = "Línea de Tiempo de la Evolución de la Arquitectura x86"
)
```

###  Repertorio de instrucciones x86
La arquitectura x86 destaca por su complejidad y flexibilidad, reflejada en un repertorio de instrucciones extenso y de longitud variable. Esto contrasta con arquitecturas RISC, donde predominan instrucciones de longitud fija y decodificación sencilla [@hennessy_computer_2012]. Aunque esta flexibilidad permite adaptaciones a diversas aplicaciones, también implica mayores desafíos en términos de implementación y eficiencia operativa.

#### Estructura de una instrucción x86
Una instrucción típica de x86 puede incluir los siguientes componentes [@stallings_computer_2013]:

  - **Prefijos**: modifican la operación principal de la instrucción. Por ejemplo, el prefijo `0x66` cambia el tamaño del operando.
  - **Código de operación (Opcode)**: indica la operación a realizar. Por ejemplo, `0x89` corresponde `MOV`.
  - **Modificadores de dirección (ModR/M y SIB)**: definen registros y direccionamiento. El byte **SIB** (Scale, Index, Base) es especialmente útil para operaciones complejas, como el acceso a matrices.
  - **Desplazamiento e inmediato**: Agregan flexibilidad en el manejo de datos, aunque aumentan la complejidad.

```{r FormatoInst, echo=FALSE, fig.cap="Formato de instrucciones del Pentium x86", fig.align = 'center', out.width = "100%"}
knitr::include_graphics(path = "images/formatoinstruccionx86.png")
```

Un ejemplo típico de instrucción es:

```{r, results='asis', echo=FALSE}
if (knitr::is_latex_output()) {
cat('
\\begin{lstlisting}
MOV AX, [BX+SI+16]
\\end{lstlisting}
')
} else {
cat('
```assembly
MOV AX, [BX+SI+16]
```
')
}
```

Esta instrucción utiliza varios componentes, que el procesador debe decodificar antes de ejecutarla. Aunque esta flexibilidad es una ventaja en términos de funcionalidad, requiere técnicas avanzadas, como predicción de saltos y paralelización, para mantener la eficiencia en procesadores modernos [@patterson_computer_2014].

## Lenguaje ensamblador
Un procesador puede interpretar y ejecutar instrucciones exclusivamente en **lenguaje máquina**, que consiste en secuencias de números binarios almacenadas en memoria. Estas instrucciones son leídas y ejecutadas directamente por el procesador. Si un programador intentara escribir código en lenguaje máquina, debería especificar manualmente cada secuencia de ceros y unos para realizar operaciones, respetando estrictamente las estructuras de memoria y los modos de direccionamiento del procesador. Este proceso no solo es tedioso, sino también altamente propenso a errores, especialmente al realizar modificaciones, ya que implicaría descifrar y reescribir las secuencias binarias [@irvine2011assembly].

Para simplificar este desafío, se desarrolló el **lenguaje ensamblador**, un lenguaje de programación de bajo nivel que permite a los programadores utilizar instrucciones más legibles mediante mnemónicos simbólicos. A diferencia del lenguaje máquina, que opera con secuencias binarias, el ensamblador emplea símbolos que representan directamente las instrucciones ejecutadas por el procesador. Cada arquitectura de procesador tiene su propio lenguaje ensamblador, generalmente diseñado por el fabricante del hardware y optimizado para la arquitectura específica [@stallings_computer_2013].

### Ensamblador
El ensamblador es un programa que traduce las instrucciones simbólicas escritas en lenguaje ensamblador a lenguaje máquina, es decir, las convierte en las secuencias binarias que el procesador puede interpretar y ejecutar. Este proceso de traducción es prácticamente directo, ya que existe una correspondencia uno a uno entre las instrucciones en ensamblador y las instrucciones en lenguaje máquina [@stallings_computer_2013]. En contraste, los lenguajes de programación de alto nivel, como C o Python, suelen generar múltiples instrucciones máquina por cada línea de código fuente, lo que los distancia más de la arquitectura subyacente.

#### Ensambladores x86
En el caso de la arquitectura x86, los programadores pueden elegir entre diversos ensambladores, como TASM (Turbo Assembler) [@tasm], MASM (Microsoft Macro Assembler) [@masm] y NASM (Netwide Assembler) [@nasm]. Aunque cada ensamblador tiene características y sintaxis particulares, todos comparten el objetivo fundamental de convertir las instrucciones ensamblador en código binario ejecutable por los procesadores x86 [@hyde2010art].

A continuación, se presenta una comparativa de las principales características de estos ensambladores:

```{r ensambladores, echo=FALSE, message=FALSE, warning=FALSE}
library(knitr)
library(kableExtra)

# Crear un data frame con la información de los ensambladores
ensambladores <- data.frame(
Característica = c(
"Desarrollador", "Año de lanzamiento", "Sistema operativo",
"Sintaxis", "Soporte de macros", "Compatibilidad",
"Capacidades adicionales", "Licencia", "Uso actual"),
TASM = c(
"Borland", "1985", "MS-DOS, Windows",
"Sintaxis similar a Intel con extensiones",
"Macros y directivas avanzadas",
"Compatibilidad con x86 antiguo",
"Integración con herramientas Borland",
"Comercial",
"Menos común, usado en entornos heredados"),
MASM = c(
"Microsoft", "1981", "MS-DOS, Windows",
"Sintaxis de Intel con soporte avanzado",
"Macros y directivas extensivas",
"Compatibilidad con x86 antiguo",
"Integración con Visual Studio",
"Comercial",
"Ampliamente usado en desarrollo Windows"),
NASM = c(
"Simon Tatham et al.", "1996", "Multiplataforma (Windows, Linux, macOS)",
"Sintaxis de Intel, modular y extensible",
"Macros avanzadas y preprocesamiento",
"Compatibilidad con x86, x86-64 y otros",
"Soporte para múltiples formatos (binario, ELF, etc.)",
"Código abierto",
"Popular en sistemas y software libre"),
stringsAsFactors = FALSE
)

# Mostrar la tabla en formato adecuado según el tipo de salida
if (knitr::is_latex_output()) {
kable(ensambladores, format = "latex", booktabs = TRUE,
caption = "Comparativa de Ensambladores x86") %>%
kable_styling(latex_options = "scale_down") %>%
column_spec(1, width = "6cm") %>%
column_spec(2:4, width = "5cm") %>%
row_spec(0, bold = TRUE)
} else {
kable(
ensambladores,
format = "html",
caption = "Comparativa de Ensambladores x86"
) %>%
kable_styling(
full_width = FALSE,
position = "center",
bootstrap_options = c("striped", "hover")
) %>%
column_spec(1, width = "20em") %>%
column_spec(2:4, width = "15em") %>%
row_spec(0, bold = TRUE)
}
```
