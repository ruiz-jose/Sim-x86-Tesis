# Estado del arte
## Arquitectura de computadoras

La arquitectura de computadoras es el estudio y diseño de los componentes de hardware y software que componen una computadora, así como la interacción entre ellos. Este campo abarca desde el diseño de circuitos y componentes individuales hasta la integración de sistemas completos. La comprensión de estos fundamentos es crucial para el desarrollo de tecnologías eficientes y avanzadas.
La arquitectura de computadoras es el campo que se encarga de diseñar y organizar los componentes fundamentales de un sistema informático, como la unidad central de procesamiento (CPU), la memoria y los dispositivos de entrada/salida. Estudiar esta disciplina nos brinda una comprensión profunda de cómo funcionan estos componentes y cómo se interconectan para formar un sistema informático.
Una razón convincente para estudiar arquitectura de computadoras es que nos permite comprender cómo funcionan los sistemas informáticos desde el nivel más bajo. Nos proporciona una comprensión profunda de los principios fundamentales, las estructuras y los componentes clave de un sistema informático. Esta comprensión nos da una visión holística del funcionamiento de una computadora y nos permite aprovechar su potencial al máximo.
Además, la arquitectura de computadoras está estrechamente relacionada con otros campos de la informática, como la programación y el desarrollo de software. Comprender la arquitectura del hardware nos permite escribir programas y algoritmos que aprovechen al máximo los recursos disponibles. Esto es especialmente importante en un mundo donde la optimización del rendimiento y la eficiencia energética son cada vez más relevantes.
Además, la arquitectura de computadoras nos brinda una base sólida para comprender y aprovechar las nuevas tendencias tecnológicas, como la computación en la nube, la inteligencia artificial y el internet de las cosas. Estudiar esta disciplina nos prepara para ser parte de la innovación tecnológica y contribuir al desarrollo de soluciones avanzadas en estos campos.
En resumen, estudiar arquitectura de computadoras nos proporciona un conocimiento profundo de los sistemas informáticos, nos capacita para diseñar sistemas eficientes y escalables, y nos prepara para aprovechar las últimas tendencias tecnológicas. Es una disciplina esencial para aquellos que desean seguir una carrera en el campo de la informática y la tecnología, y contribuir al avance de la sociedad digital en la que vivimos.
Además, el estudio de la arquitectura de computadoras nos brinda una base sólida para comprender y resolver problemas de rendimiento y eficiencia en los sistemas informáticos. Al adentrarnos en los conceptos de paralelismo, pipelining, caché y optimización de código, aprendemos a diseñar sistemas más eficientes y a mejorar el rendimiento de las aplicaciones.
Otro motivo relevante para estudiar arquitectura de computadoras es la capacidad de contribuir al desarrollo de nuevas tecnologías. La innovación en esta área ha sido constante, desde la miniaturización de componentes hasta el diseño de arquitecturas avanzadas como las basadas en computación cuántica. Al obtener conocimientos en arquitectura, podemos ser parte de esta evolución tecnológica y contribuir a la creación de sistemas más poderosos y eficientes.
Por último, el estudio de la arquitectura de computadoras nos proporciona una base sólida para comprender otros campos relacionados, como la seguridad informática y los sistemas embebidos. Estos conocimientos son cada vez más demandados en la industria, lo que abre oportunidades laborales en empresas de desarrollo de software, fabricantes de hardware, centros de investigación y muchas otras áreas relacionadas con la tecnología.
En conclusión, estudiar arquitectura de computadoras es fundamental para comprender el funcionamiento de los sistemas informáticos, resolver problemas de rendimiento y eficiencia, contribuir a la innovación tecnológica y acceder a una amplia gama de oportunidades laborales. Es una disciplina emocionante que impulsa la evolución de la tecnología y nos permite ser parte activa de este cambio.

###   Arquitectura x86
La arquitectura x86 es una de las más influyentes y ampliamente utilizadas en el ámbito de las computadoras de escritorio y servidores. Su historia se remonta a 1978 con el lanzamiento del procesador Intel 8086, que introdujo una arquitectura de 16 bits. Esta arquitectura evolucionó significativamente con la introducción del Intel 80386 en 1985, que marcó el inicio de la era de 32 bits (x86-32). Posteriormente, AMD amplió esta arquitectura a 64 bits con su AMD64, una extensión que Intel adoptó como Intel 64 [14, 16].

####   Contextualización Histórica y Evolución de la Arquitectura x86

La compatibilidad hacia atrás de la arquitectura x86 ha sido un factor clave en su éxito, permitiendo la ejecución de aplicaciones de 16, 32 y 64 bits en un mismo sistema. Esta característica ha protegido las inversiones en aplicaciones y sistemas operativos desarrollados para la arquitectura x86, consolidando su relevancia en la industria [14,16].

| Procesador | Año de Lanzamiento | Número de Bits | Nuevas Características |
|------------|---------------------|----------------|------------------------|
| Intel 8086 | 1978                | 16             | Arquitectura inicial   |
| Intel 80386| 1985                | 32             | Memoria virtual        |
| AMD64      | 2003                | 64             | Extensiones de 64 bits |


La evolución de la arquitectura x86 ha estado marcada por una serie de hitos importantes que han impulsado la informática hacia nuevas alturas. Tras el Intel 8086, el lanzamiento del Intel 80286 en 1982 introdujo modos de operación adicionales que mejoraron la eficiencia y el manejo de memoria. Luego, en 1989, el Intel 80486 incorporó una unidad de punto flotante integrada y una mejor caché, lo que aumentó significativamente el rendimiento.
La serie Pentium, iniciada en 1993, llevó la arquitectura x86 a nuevos niveles de rendimiento y eficiencia, incorporando características avanzadas como la ejecución superescalar y la predicción de saltos. Los avances continuaron con el Pentium Pro en 1995, que mejoró la arquitectura con ejecución fuera de orden y una caché L2 integrada.
En la década de 2000, la arquitectura x86 se adaptó a las demandas de la computación moderna con la introducción del Intel Core, que optimizó el rendimiento y la eficiencia energética. AMD también jugó un papel crucial con su serie Athlon y la introducción de AMD64, que llevó la arquitectura x86 a 64 bits, permitiendo un acceso a mayor memoria y mejorando el rendimiento en aplicaciones intensivas.

library(knitr)


evolucion_x86 <- data.frame(
  Año = c(1978, 1982, 1985, 1989, 1993, 1995, 2003, 2006),
  Procesador = c("Intel 8086", "Intel 80286", "Intel 80386", "Intel 80486", "Intel Pentium", "Intel Pentium Pro", "AMD64", "Intel Core"),
  `Innovación Principal` = c(
    "Introducción de la arquitectura x86, 16 bits",
    "Modos de operación adicionales",
    "Arquitectura de 32 bits, memoria virtual",
    "Unidad de punto flotante integrada, mejor caché",
    "Ejecución superescalar, predicción de saltos",
    "Ejecución fuera de orden, caché L2 integrada",
    "Extensiones a 64 bits, mayor acceso a memoria",
    "Optimización de rendimiento y eficiencia energética"
  )
)

kable(evolucion_x86, caption = "Línea de Tiempo de la Evolución de la Arquitectura x86")

####  Comparación con Otras Arquitecturas
La arquitectura x86 ha dominado el mercado de las computadoras de escritorio y servidores durante décadas, pero existen otras arquitecturas importantes que también han tenido un impacto significativo en la informática. Comparar x86 con arquitecturas como ARM, MIPS y RISC-V nos permite entender mejor sus ventajas y desventajas.
comparacion_arquitecturas <- data.frame(
  Característica = c("Eficiencia Energética", "Complejidad ISA", "Rendimiento", "Compatibilidad", "Áreas de Aplicación"),
  x86 = c("Moderada", "Alta", "Alto", "Alta (hacia atrás)", "Escritorio, servidores"),
  ARM = c("Alta", "Baja", "Moderado", "Moderada", "Dispositivos móviles"),
  MIPS = c("Moderada", "Moderada", "Moderado", "Moderada", "Sistemas embebidos"),
  `RISC-V` = c("Alta", "Baja", "Variable", "Alta", "Investigación, embebidos")
)
kable(comparacion_arquitecturas, caption = "Comparación de Arquitecturas")

La arquitectura ARM, conocida por su eficiencia energética, ha ganado popularidad en dispositivos móviles y sistemas embebidos. MIPS, aunque menos prominente en la actualidad, se ha utilizado en sistemas embebidos y educación. RISC-V, una arquitectura abierta y libre, ha surgido como una alternativa flexible y eficiente, especialmente en investigación y aplicaciones embebidas.

####  Aplicaciones y Casos de Uso de la Arquitectura x86
La arquitectura x86 ha demostrado ser extremadamente versátil y ha encontrado aplicaciones en una amplia variedad de campos. Su capacidad para manejar tareas complejas y su compatibilidad hacia atrás han sido factores clave en su adopción.

casos_uso_x86 <- data.frame(
  `Casos de Uso` = c(
    "Servidores: La arquitectura x86 domina el mercado de servidores debido a su capacidad para manejar grandes cargas de trabajo y su compatibilidad con una amplia gama de software empresarial.",
    "Computadoras Personales: Desde su introducción, la arquitectura x86 ha sido la columna vertebral de las computadoras personales, proporcionando el rendimiento necesario para aplicaciones de productividad, juegos y multimedia.",
    "Sistemas Embebidos: Con la miniaturización y la eficiencia mejorada, los procesadores x86 se han integrado en sistemas embebidos como dispositivos médicos, sistemas de control industrial y dispositivos de telecomunicaciones."
  )
)
kable(casos_uso_x86, col.names = NULL, caption = "Casos de Uso Notables de la Arquitectura x86")

####  Impacto de la Arquitectura x86 en la Industria del Software
La arquitectura x86 ha tenido un impacto profundo en el desarrollo de software. Los sistemas operativos populares como Windows y Linux están optimizados para x86, lo que ha influido en el desarrollo y la optimización de aplicaciones para esta arquitectura.
Influencia en el Desarrollo de Software:
Optimización del Rendimiento: Los desarrolladores de software han trabajado estrechamente con las características de la arquitectura x86 para optimizar el rendimiento de sus aplicaciones. Esto incluye el uso de instrucciones específicas de x86 y la optimización para cachés y pipelines.
Compatibilidad y Soporte: La compatibilidad hacia atrás de x86 ha permitido la continuidad de aplicaciones y sistemas operativos, protegiendo las inversiones en software y facilitando las actualizaciones.
Ecosistema de Desarrollo: Un amplio ecosistema de herramientas de desarrollo, bibliotecas y frameworks ha sido construido alrededor de la arquitectura x86, facilitando el desarrollo de aplicaciones de alto rendimiento y su depuración.

####  Futuro de la Arquitectura x86
La arquitectura x86 sigue evolucionando para enfrentar los desafíos de la computación moderna. Las tendencias emergentes como la computación cuántica, la inteligencia artificial y la computación en la nube presentan tanto oportunidades como desafíos para x86.
Desafíos y Oportunidades Futuras:
Computación Cuántica: Aunque aún en sus primeras etapas, la computación cuántica podría complementar las arquitecturas tradicionales como x86, especialmente en aplicaciones que requieren capacidades de procesamiento extremo.
Inteligencia Artificial: La integración de aceleradores de IA y el soporte para operaciones de aprendizaje profundo en hardware x86 están siendo explorados para mejorar el rendimiento en aplicaciones de IA.
Computación en la Nube: La arquitectura x86 sigue siendo relevante en la infraestructura de la nube, aunque enfrenta competencia de arquitecturas más eficientes como ARM.
En resumen, la arquitectura x86 ha sido fundamental en la evolución de la informática, proporcionando una plataforma versátil y poderosa para una amplia variedad de aplicaciones. Su continua evolución y adaptación a las nuevas tecnologías aseguran su relevancia en el futuro.

####  Repertorio de instrucciones x86
El repertorio de instrucciones, o ISA (Instruction Set Architecture), es fundamental para la interacción entre el software y el hardware de una computadora. En el caso de la arquitectura x86, este conjunto de instrucciones ha evolucionado para incluir una amplia gama de operaciones que permiten un control detallado del hardware. La ISA x86 es conocida por su complejidad y flexibilidad, lo que la hace ideal para una variedad de aplicaciones.
Por ello, la enseñanza de la arquitectura x86 es de gran relevancia en la asignatura Arquitecturas de Computadoras debido a los diferentes temas que aborda.

#### Ejemplos de Instrucciones x86
El repertorio de instrucciones x86 incluye una variedad de instrucciones para realizar operaciones aritméticas, lógicas, de control y de manejo de memoria. Algunos ejemplos son:

- `MOV`: Mueve datos de una ubicación a otra.
- `ADD`: Suma dos valores.
- `SUB`: Resta un valor de otro.
- `JMP`: Salta a una dirección específica.

## Lenguaje ensamblador
Un procesador puede interpretar y ejecutar solo instrucciones máquina. Estas instrucciones son simplemente secuencias de números binarios almacenados en la computadora y son leídas por el procesador e interpretadas por él. Si un programador quisiera programar directamente en el lenguaje máquina, necesita introducir los programas como datos binarios. Esto requeriría escribir las sentencias que necesita realizar el procesador directamente en binarios, por lo tanto, conocer la secuencia de ceros y unos para cada operación escribiéndose ordenadamente, además de respetar la estructura de memoria y direccionamientos del procesador. Esto sin duda es un trabajo complejo, difícil, pesado y muy susceptible a errores. Adicionalmente, una vez que se requiera realizar modificaciones, su lectura implica ir traduciendo estas secuencias de ceros y unos a su correspondiente instrucción, lo que es doblemente dificultoso. 
El lenguaje ensamblador es un lenguaje de programación de bajo nivel que permite a los programadores escribir instrucciones comprensibles por el procesador. A diferencia del lenguaje máquina, que utiliza secuencias de números binarios, el ensamblador emplea mnemónicos simbólicos que hacen que el código sea más legible y manejable para los humanos. Cada arquitectura de procesador tiene su propio lenguaje ensamblador que usualmente es definida por el fabricante de hardware, por lo tanto es específica de cierta arquitectura de la computadora física. Un programa llamado ensamblador es usado para traducir sentencias del lenguaje ensamblador al código de máquina de la computadora. El ensamblador realiza una traducción casi directa uno a uno desde las sentencias mnemónicas a las instrucciones y datos de máquina. Esto está en contraste con los lenguajes de alto nivel, en los cuales una sola declaración generalmente da lugar a muchas instrucciones de máquina. 
El código fuente generado en mnemotécnicos debe ser traducido a lenguaje máquina para poder ser ejecutado por la computadora. Este proceso lo realizan programas denominados ensambladores. Si nos ubicamos en la arquitectura x86 encontraremos diferentes lenguajes ensambladores. De ahí los diferentes productos ofrecidos, entre ellos, TASM (Turbo Assembler), MASM (Microsoft Macro Assembler) y NASM (Netwide Assembler). Cada uno ofrece diferentes características y beneficios, adaptándose a diversas necesidades y preferencias de los programadores. Estos ensambladores convierten el código simbólico en código máquina, permitiendo su ejecución en el hardware específico de la arquitectura x86. 

##  Simulación
La simulación es una herramienta esencial en múltiples campos como la medicina, el ámbito militar, el entretenimiento y la educación. Permite a los profesionales comprender el funcionamiento de un sistema, realizar análisis predictivos y responder preguntas del tipo "qué pasaría si", generando hipótesis sobre cómo o por qué ocurren ciertos fenómenos. Según Banks et al. (2001), la simulación se define como el proceso de imitar el comportamiento de un sistema a lo largo del tiempo. Este proceso requiere primero desarrollar un modelo conceptual que capture las características y comportamientos del sistema real, mientras que la simulación representa la evolución de este modelo conforme el tiempo avanza. La capacidad de replicar y analizar sistemas complejos sin necesidad de intervenir directamente en ellos es lo que hace que la simulación sea una metodología indispensable para ingenieros, diseñadores y gerentes en el mundo digital actual [1,3].
Con los avances en el mundo digital, la simulación se ha convertido en una metodología de solución de problemas indispensables para ingenieros, docentes, diseñadores y gerentes. La complejidad intrínseca de los sistemas informáticos los hace difícil comprender y costosos de desarrollar sin utilizar simulación [3].

En la industria automotriz, la simulación es fundamental para el diseño y prueba de sistemas de seguridad, como airbags y frenos. Un modelo virtual del automóvil y sus componentes permite realizar pruebas de colisión y evaluar el rendimiento de los sistemas de seguridad sin la necesidad de llevar a cabo costosas pruebas físicas. Además, la simulación permite optimizar el diseño de motores, analizar el flujo aerodinámico y prever el comportamiento de los materiales en condiciones extremas.
Ejemplo Adicional:
En el campo de la aviación, la simulación se utiliza para entrenar pilotos en simuladores de vuelo que replican condiciones reales sin riesgos. También se emplea en el diseño de aeronaves para evaluar la aerodinámica y el rendimiento de nuevos diseños bajo diversas condiciones de vuelo. Estos ejemplos demuestran cómo la simulación puede reducir costos, mejorar la seguridad y acelerar el desarrollo de productos complejos.

### Herramientas de Simulación en la Educación
Herramientas como Simulink, Proteus, y Logisim permiten a los estudiantes interactuar con modelos virtuales de circuitos y sistemas informáticos, facilitando la comprensión de la arquitectura interna y las operaciones de una computadora.

## Simulación aplicada a la enseñanza de arquitectura de computadoras
Los estudiantes de la asignatura Arquitectura de Computadoras deben no solo conocer la estructura y el funcionamiento interno de las computadoras, sino también tener una experiencia práctica activa con dicha arquitectura. Esta experiencia práctica es crucial para desarrollar competencias en el uso de herramientas y técnicas relacionadas con el hardware. Sin embargo, la implementación de laboratorios físicos con el hardware necesario puede ser costosa y requiere tiempo considerable para que los alumnos adquieran las habilidades necesarias.
Para superar estas limitaciones, se han desarrollado numerosos simuladores que proporcionan experiencias de aprendizaje valiosas al replicar el funcionamiento y la estructura de las computadoras. Simuladores como SimpleScalar, SPIM y GEM5 permiten a los estudiantes experimentar con arquitecturas complejas y técnicas avanzadas como el pipelining y la ejecución fuera de orden. Estas herramientas facilitan la comprensión de los conceptos teóricos a través de la interacción práctica, proporcionando un entorno seguro y accesible para la exploración y el aprendizaje [17].
### Uso de la Simulación para Enseñar Pipelining
El pipelining es una técnica utilizada en las CPUs modernas para mejorar el rendimiento. Utilizando simuladores como SimpleScalar, los estudiantes pueden visualizar cómo las instrucciones se ejecutan en diferentes etapas del pipeline, y cómo se manejan las dependencias de datos y los riesgos de control.

## El Formalismo DEVS (Discrete Event System Specification)
DEVS, la abreviación de Discrete Event System Specification, es un formalismo modular y jerárquico para el modelado y análisis de sistemas que pueden ser representados como sistemas de eventos discretos, sistemas de estado continuo o sistemas híbridos. Este formalismo, desarrollado por Bernard P. Zeigler en los años 70, extiende el concepto de las máquinas de Moore al proporcionar una estructura para modelar sistemas complejos mediante la utilización de eventos cronometrados.
### Descripción del Formalismo DEVS
El formalismo DEVS define el comportamiento de un sistema real utilizando eventos de entrada y salida, y transiciones entre estados concretos. Un sistema en DEVS está compuesto por modelos atómicos y acoplados. Los modelos atómicos representan las unidades básicas de comportamiento, mientras que los modelos acoplados consisten en combinaciones de modelos atómicos y/o otros modelos acoplados. Esta estructura jerárquica facilita la gestión y análisis de sistemas complejos, permitiendo la prueba de subsistemas de manera aislada antes de integrarlos en el sistema completo.
Bajo un punto de vista general, un modelo DEVS está caracterizado por generar eventos de salida Y , en relación con el estado en el que se encuentre S y las entradas recibidas X, cada cierto tiempo.

Figura 3.4: Representación simple de un modelo DEVS
### Aplicaciones del Formalismo DEVS
El formalismo DEVS es aplicable a una amplia gama de sistemas, desde redes de comunicación hasta procesos de manufactura. Por ejemplo, en una red de comunicación, un modelo DEVS puede simular el enrutamiento de paquetes de datos y la gestión de congestiones. En la manufactura, un modelo DEVS puede representar el flujo de materiales y el control de calidad en una línea de producción, ayudando a identificar cuellos de botella y optimizar procesos.
### Ejemplo de Modelo DEVS
Consideremos un sistema de colas en un banco, donde los clientes llegan, esperan en la fila y son atendidos por cajeros. Un modelo DEVS puede representar los eventos de llegada de clientes, la asignación a los cajeros y el tiempo de servicio, permitiendo evaluar el tiempo de espera y la utilización de los recursos. Este ejemplo ilustra cómo DEVS puede ser utilizado para mejorar la eficiencia operativa y la satisfacción del cliente mediante la optimización del flujo de trabajo y la asignación de recursos.

### Aporte pedagógico
En el ámbito educativo, transmitir los fundamentos teóricos de la organización y arquitectura interna de las computadoras puede ser un desafío debido a la complejidad de los procesos involucrados. Los métodos tradicionales de enseñanza, como el uso de pizarras, libros de texto y diapositivas, a menudo tienen una capacidad limitada para representar estos conceptos de manera efectiva. Esto requiere que los estudiantes tengan un alto nivel de abstracción para desarrollar un modelo mental adecuado para capturar la organización y arquitectura interna de las computadoras [4,5].
La integración de nuevas tecnologías como recurso didáctico es crucial para facilitar el aprendizaje. Las herramientas de simulación permiten a los estudiantes relacionar conceptos abstractos con situaciones reales, situándose en un contexto que imita aspectos de la realidad. Este enfoque pedagógico facilita la detección de problemáticas y el desarrollo de habilidades a través del trabajo exploratorio, la inferencia y el aprendizaje por descubrimiento. Simuladores como Simulink, Proteus y Logisim juegan un papel esencial en la enseñanza de la arquitectura de computadoras, proporcionando una representación visual e interactiva que enriquece la comprensión teórica y práctica de los estudiantes [6,7].
El uso de herramientas de simulación en la enseñanza para procesos dinámicos complejos, como las operaciones intrínsecas de la computadora, que permiten representar de forma visual e interactiva la organización y arquitectura interna de la computadora, facilitando así la comprensión de su funcionamiento por parte de los alumnos y el desarrollo de los temas por parte del docente. En este contexto, los simuladores juegan una pieza clave en el campo de la Arquitectura de Computadoras, permitiendo conectar fundamentos teóricos con la experiencia práctica, implicando abstracciones y haciendo más rica la labor docente.
