# Estado del arte {#arte}
Este capítulo explora el estado del arte en la arquitectura de computadoras, con un enfoque especial en la evolución de la arquitectura x86 y el uso de herramientas de simulación en la educación. El análisis proporciona una visión integral de cómo estos elementos han influido en la enseñanza de la informática, mejorando la comprensión de conceptos complejos y la aplicación práctica en entornos educativos.

A continuación, se abordará el papel fundamental que desempeñan las herramientas de simulación en la enseñanza de la arquitectura de computadoras. Estas herramientas facilitan la comprensión de conceptos complejos y permiten a los estudiantes interactuar con sistemas simulados, proporcionando una experiencia práctica valiosa que de otro modo sería difícil de obtener. Se examinarán las herramientas de simulación más destacadas y su aplicación en entornos educativos, evaluando sus beneficios y limitaciones.

Finalmente, se explorarán las tendencias actuales y futuras en la enseñanza de la arquitectura de computadoras, destacando las innovaciones tecnológicas y metodológicas que están revolucionando las prácticas educativas en este campo. Se analizarán enfoques pedagógicos innovadores y estrategias de enseñanza que aprovechan las herramientas digitales y la simulación para mejorar la comprensión y el rendimiento de los estudiantes.

## Arquitectura de Computadoras
La arquitectura de computadoras es el campo que se dedica al estudio y diseño detallado de los componentes físicos (hardware) y lógicos (software) de un sistema informático, con un enfoque particular en la optimización de su interacción para lograr sistemas más eficientes y de alto rendimiento. Este ámbito abarca desde el diseño de circuitos electrónicos hasta la integración de sistemas completos, siendo fundamental para el desarrollo de tecnologías avanzadas y sostenibles [@hennessy_computer_2012] [@stallings_computer_2013].

Entender la arquitectura de una computadora implica conocer atributos del sistema visibles al programador, como el conjunto de instrucciones (por ejemplo, la arquitectura x86 o ARM), la cantidad de bits utilizados para representar datos (como en sistemas de 32 o 64 bits), los mecanismos de entrada/salida, las técnicas de direccionamiento (como direccionamiento directo o segmentado), y la gestión de la jerarquía de memoria [@null_essentials_2014]. Además, conceptos como el paralelismo y la eficiencia energética son cruciales para optimizar el rendimiento y el desarrollo de software y sistemas operativos eficientes [@hennessy_computer_2012] [@patterson_computer_2014].

La arquitectura de computadoras se distingue de la organización interna del hardware. Mientras que la **arquitectura** define los atributos visibles al programador y las abstracciones necesarias para desarrollar software eficiente, la **organización** se refiere a cómo se implementa físicamente esa arquitectura: cómo se interconectan y operan los componentes físicos, incluyendo la disposición de la memoria, las señales de control y las unidades de procesamiento, para cumplir con los objetivos de rendimiento y funcionalidad del sistema [@tanenbaum_structured_2013] [@murdocca_principles_2000].

Estudiar la arquitectura de computadoras permite no solo comprender el funcionamiento y la estructura de los sistemas informáticos desde su nivel más básico, sino también adaptar y optimizar estos sistemas para nuevas tendencias tecnológicas como la computación en la nube, la inteligencia artificial y el Internet de las cosas. La arquitectura efectiva es el cimiento que permite a estas tecnologías alcanzar su máximo potencial, contribuyendo activamente a la innovación tecnológica [@hennessy_computer_2012] [@stallings_computer_2013].

La comprensión profunda de la arquitectura y organización de los computadores es fundamental para cualquier profesional en el campo de la informática. No solo capacita para diseñar sistemas más eficientes y escalables, sino que también proporciona una base sólida para comprender otros campos relacionados, como la seguridad informática y los sistemas embebidos, que son cada vez más demandados en la industria [@patterson_computer_2014]. En última instancia, el estudio de la arquitectura de computadoras abre un amplio espectro de oportunidades laborales en diversas áreas tecnológicas, permitiendo a los profesionales ser parte activa en la evolución de la sociedad digital.

En conclusión, estudiar la arquitectura de computadoras no solo es esencial para comprender el funcionamiento de los sistemas informáticos y resolver problemas de rendimiento y eficiencia, sino que también capacita a los profesionales para diseñar soluciones innovadoras en áreas como la inteligencia artificial, la ciberseguridad y los sistemas embebidos. Este conocimiento es fundamental para enfrentar los desafíos tecnológicos del futuro, abriendo un amplio espectro de oportunidades laborales en un mercado que valora la capacidad de crear y optimizar sistemas computacionales más poderosos y eficientes [@stallings_computer_2013].

## Tipos de arquitecturas
El estudio de diferentes arquitecturas de computadoras es fundamental para comprender sus ventajas y limitaciones en distintos contextos de aplicación. Esta comparación permite a los desarrolladores y diseñadores de sistemas elegir la arquitectura más adecuada para sus necesidades, considerando factores como la eficiencia energética, la complejidad del hardware, y las aplicaciones específicas.

### Arquitectura x86
La arquitectura x86 ha dominado el mercado de las computadoras de escritorio y servidores durante décadas, gracias a su capacidad para ofrecer un alto rendimiento y su amplia compatibilidad con software existente. La complejidad de su conjunto de instrucciones (ISA) permite una mayor flexibilidad, aunque a costa de una mayor complejidad en el diseño del hardware. Su eficiencia energética es moderada, lo que la hace menos adecuada para dispositivos móviles y más apropiada para entornos donde el rendimiento es la principal preocupación [@hennessy_computer_2012].

### Arquitectura ARM
La arquitectura ARM es conocida por su alta eficiencia energética, lo que la ha hecho muy popular en dispositivos móviles, como smartphones y tablets, y en sistemas embebidos. ARM utiliza un conjunto de instrucciones reducido (RISC), lo que simplifica el diseño del hardware y reduce el consumo de energía. Aunque su rendimiento es moderado en comparación con x86, la arquitectura ARM es ideal para aplicaciones donde la eficiencia energética es crucial [@patterson_computer_2014].

### Arquitectura MIPS
MIPS es otra arquitectura basada en RISC que ha sido ampliamente utilizada en sistemas embebidos y en la educación. Aunque ha perdido prominencia frente a otras arquitecturas como ARM, MIPS sigue siendo relevante en ciertos nichos debido a su simplicidad y efectividad. Su conjunto de instrucciones es moderadamente complejo, lo que permite un equilibrio entre rendimiento y eficiencia energética, aunque su compatibilidad y soporte en la industria son más limitados [@hennessy_computer_2012].

### Arquitectura RISC-V
RISC-V es una arquitectura emergente que ha ganado atención por ser una ISA abierta y libre, lo que permite a los desarrolladores y fabricantes adaptar y personalizar la arquitectura según sus necesidades. Al igual que ARM, RISC-V se basa en el paradigma RISC, lo que le otorga una alta eficiencia energética y una baja complejidad de hardware. Su flexibilidad la convierte en una opción atractiva para la investigación, la educación, y aplicaciones embebidas. Además, RISC-V ofrece una compatibilidad creciente gracias a su adopción por parte de la comunidad global de desarrolladores [@waterman_risc-v_2014].

```{r tabla-comparacion-cpu, echo=FALSE, message=FALSE, warning=FALSE}
library(knitr)

comparacion_cpu <- data.frame(
  Característica = c("Eficiencia Energética", "Complejidad ISA", "Rendimiento", "Compatibilidad", "Áreas de Aplicación"), # nolint: line_length_linter.
  x86 = c("Moderada", "Alta", "Alto", "Alta (hacia atrás)", "Escritorio, servidores"),
  ARM = c("Alta", "Baja", "Moderado", "Moderada", "Dispositivos móviles"),
  MIPS = c("Moderada", "Moderada", "Moderado", "Moderada", "Sistemas embebidos"),
  `RISC-V` = c("Alta", "Baja", "Variable", "Alta", "Investigación, embebidos")
)

kable(comparacion_cpu, format = "markdown", caption = "Comparación de Arquitecturas")
```

Cada una de estas arquitecturas ofrece un conjunto único de características que las hace más o menos adecuadas para diferentes aplicaciones. La elección de la arquitectura correcta puede tener un impacto significativo en el éxito de un proyecto, ya sea en términos de rendimiento, eficiencia energética o compatibilidad [@patterson_computer_2017].

## Repertorio de Instrucciones
El repertorio de instrucciones, conocido como **ISA (Instruction Set Architecture)**, define el conjunto de operaciones que un procesador puede ejecutar y cómo se codifican dichas operaciones. Este conjunto incluye instrucciones aritméticas, lógicas, de control y de manipulación de datos, así como los modos de direccionamiento y formatos de las instrucciones. El diseño de un ISA tiene un impacto considerable en el rendimiento, la eficiencia energética y la flexibilidad de la arquitectura de un procesador [@hennessy_quantitative_2012; @null_essentials_2014; @stallings_computer_2013].

Entre las características clave que deben considerarse en el diseño de un repertorio de instrucciones están las siguientes:

- **Tipos de Operandos**: Se refiere a los diversos tipos de datos que las instrucciones pueden manipular, como enteros, números en punto flotante, caracteres o direcciones de memoria. Es crucial diseñar un repertorio de instrucciones que soporte eficientemente diferentes tipos de operando.

- **Tipos de Operaciones**: Incluye las operaciones que el procesador puede realizar, como aritmética (suma, resta), lógica (AND, OR), control (saltos, llamadas a subrutinas) y operaciones de manipulación de datos (movimiento de datos, almacenamiento, carga).

- **Formato de las Instrucciones**: La estructura de una instrucción determina la longitud, el número de operandos y los modos de direccionamiento. Esto tiene un impacto directo en la eficiencia y la complejidad del procesador.

- **Modos de Direccionamiento**: Definen cómo se especifican los operandos en las instrucciones. Modos comunes incluyen inmediato, directo, indirecto y relativo. Cada uno ofrece diferentes ventajas en términos de flexibilidad y eficiencia.

### Funciones del Repertorio de Instrucciones
El repertorio de instrucciones no solo define qué operaciones puede realizar un procesador, sino también cómo se organizan y ejecutan [@stallings_computer_2013]. Las funciones principales incluyen:

- **Control de la CPU**: Instrucciones de control que gestionan la secuencia de ejecución, interrupciones y llamadas a subrutinas.

- **Interacción con la Memoria**: Las instrucciones permiten que la CPU cargue y almacene datos desde y hacia la memoria principal, aspecto crítico para la ejecución de programas.

- **Gestión de Datos**: Las operaciones aritméticas, lógicas y de comparación son esenciales para la manipulación de datos. El diseño adecuado del repertorio puede simplificar y acelerar estas operaciones.

- **Optimización del Rendimiento**: Un repertorio de instrucciones eficiente minimiza el número de instrucciones para completar una tarea, mejorando el uso de energía y los recursos del sistema [@hennessy_quantitative_2012].

### Modos de direccionamiento
Los modos de direccionamiento son fundamentales para definir cómo una CPU accede a los datos para ejecutar una instrucción [@stallings_computer_2013 ; @hennessy_design_2014 ]. Algunos modos comunes incluyen:

a) **Inmediato**: El operando está embebido en la propia instrucción, proporcionando acceso rápido a valores constantes pequeños.

b) **Directo**: La dirección de memoria del operando está incluida en la instrucción. Es sencillo, pero limita el rango de direcciones accesibles directamente.

c) **Indirecto**: La dirección de memoria apunta a otra dirección donde se encuentra el operando real, permitiendo un acceso más amplio, pero a un costo de tiempo.

d) **Registro**: Utiliza un registro en lugar de una dirección de memoria, acelerando el acceso a datos.

e) **Registro Indirecto**: Similar al modo indirecto, pero con la dirección almacenada en un registro.

f) **Con Desplazamiento**: Combina una dirección base con un desplazamiento, útil en estructuras de datos como arrays.

g) **Pila**: Calcula la dirección del operando en función de la ubicación actual en la pila, usado comúnmente en llamadas a subrutinas.

Estos modos se ilustran en la figura \@ref(figFlujo)  :
- A = contenido de un campo de dirección en la instrucción
- R = contenido de un campo de dirección en la instrucción que referencia a un registro
- EA = dirección real (efectiva) de la posición que contiene el operando que se referencia
- (X) = contenido de la posición de memoria X o del registro X
 
{#figFlujo} 
```{r flujo, echo=FALSE, fig.cap="Modos de direccionamiento", fig.align = 'center', out.width = "100%"}
knitr::include_graphics(path = "images/modosdireccionamiento.png")
```

### Formato de las Instrucciones
El formato de las instrucciones determina cómo se estructuran las instrucciones en términos de longitud, número de operandos y campos adicionales como el código de operación (**opcode**)[@hennessy_quantitative_2012; @tanenbaum_structured_2012]. El formato tiene un impacto directo en la complejidad del diseño del procesador:

- **Longitud de la Instrucción**: Las instrucciones pueden ser de longitud fija o variable. Las instrucciones de longitud fija son más fáciles de decodificar, pero pueden desperdiciar espacio en casos donde no se necesite la flexibilidad de una instrucción larga.

- **Cantidad de Operandos**: Dependiendo de la arquitectura, las instrucciones pueden manejar desde cero hasta tres o más operandos, impactando tanto la flexibilidad como la complejidad del procesador.

- **Campos de Instrucción**: Un campo común es el **opcode**, que indica la operación a realizar, mientras que los operandos pueden estar representados en campos adicionales. Otros campos pueden incluir modos de direccionamiento o flags de condición.


#### Filosofías CISC y RISC
Las arquitecturas del repertorio de instrucciones son un componente crucial en el diseño de procesadores. Dos de las filosofías de diseño más influyentes en este ámbito son **CISC (Complex Instruction Set Computing)** y **RISC (Reduced Instruction Set Computing)**. Mientras que CISC busca minimizar la cantidad de instrucciones necesarias para realizar una tarea, RISC simplifica el conjunto de instrucciones para optimizar la velocidad y la eficiencia energética. Esta sección profundiza estos dos enfoques y sus implicaciones en el diseño de procesadores [@hennessy_quantitative_2012; @hennessy_organization_2014].

### CISC: Reducción de Instrucciones, Aumento de Complejidad
En las arquitecturas **CISC**, como la x86, el objetivo principal es reducir la cantidad de instrucciones necesarias para realizar operaciones complejas. Esto se logra implementando instrucciones que pueden realizar varias operaciones en un solo ciclo de instrucción, lo cual reduce el código que debe escribir un programador. Sin embargo, esta ventaja tiene un costo: la **decodificación** y **ejecución** de instrucciones CISC requiere un hardware más complejo. Además, las instrucciones de longitud variable, comunes en CISC, pueden incrementar el tiempo de decodificación, generando cuellos de botella en el pipeline.

Por ejemplo, los procesadores **x86** han evolucionado hacia una arquitectura híbrida, utilizando microcódigo para descomponer las instrucciones CISC en operaciones más simples, similares a las de una arquitectura RISC. Esto mejora la eficiencia de ejecución en algunos contextos, pero sigue siendo una arquitectura más costosa en términos de diseño y energía [@hennessy_organization_2014].

### RISC: Simplicidad para Mayor Velocidad y Eficiencia Energética
Por otro lado, las arquitecturas **RISC** como **ARM** y **MIPS** se centran en un conjunto de instrucciones más reducido y de longitud fija, lo que simplifica la decodificación y permite ejecutar instrucciones en un solo ciclo de reloj. Esta simplicidad también permite implementar técnicas avanzadas de **pipelining** y **predicción de ramas** con mayor facilidad, mejorando el rendimiento en operaciones básicas. A nivel de hardware, RISC facilita la **optimización** y el uso de energía de manera más eficiente que CISC, lo que es especialmente importante en dispositivos móviles y embebidos [@hennessy_quantitative_2012].

La filosofía de diseño RISC ha permitido que procesadores como **ARM** dominen el mercado de dispositivos móviles, donde la eficiencia energética es crítica. El enfoque de RISC en operaciones simples y repetitivas, con un CPI (ciclos por instrucción) bajo, ha sido un factor clave para esta adopción [@hennessy_quantitative_2012].

## Impacto del Formato de Instrucciones en el Rendimiento
Una de las diferencias clave entre CISC y RISC radica en el formato de las instrucciones. En *Structured Computer Organization* de Tanenbaum se detalla cómo el **formato de longitud fija**, característico de las arquitecturas RISC, simplifica la **decodificación** y mejora el rendimiento general del procesador [@tanenbaum_structured_2013].

### Formato de Longitud Fija en RISC
En las arquitecturas **RISC**, todas las instrucciones tienen la misma longitud, lo que facilita la decodificación y permite que el procesador mantenga un flujo continuo de instrucciones a través del pipeline. Este enfoque no solo reduce la latencia, sino que también mejora la predictibilidad del rendimiento, lo que es esencial para arquitecturas altamente escalables y eficientes. Además, este formato simplificado permite una mejor **utilización de la memoria caché**, ya que las instrucciones ocupan menos espacio en la memoria y permiten un acceso más rápido.

### Formato de Longitud Variable en CISC
Por el contrario, las arquitecturas **CISC** como **x86** utilizan un **formato de longitud variable** para proporcionar flexibilidad en las instrucciones. Esto permite que las arquitecturas CISC ofrezcan una variedad más amplia de operaciones con menos líneas de código. Sin embargo, la flexibilidad tiene un costo: las instrucciones de longitud variable requieren un tiempo de decodificación más largo y complican la implementación del pipeline, lo que afecta negativamente al rendimiento [@tanenbaum_structured_2013]. 

Por ejemplo, en un procesador x86, la decodificación de instrucciones de longitud variable puede ser un cuello de botella, particularmente cuando el pipeline se interrumpe debido a errores de predicción de ramas. Aunque esto se puede mitigar mediante técnicas avanzadas como la predicción dinámica de saltos y el prefetching, el impacto en el rendimiento sigue siendo significativo.

## Ejemplos Prácticos de Modos de Direccionamiento
Los **modos de direccionamiento** permiten a los procesadores acceder a datos de manera eficiente y flexible. En *Computer Organization and Architecture* de William Stallings, se analizan en detalle varios modos de direccionamiento, como el **inmediato**, **indirecto** y **relativo**. A continuación se incluyen ejemplos prácticos de cómo estos modos se utilizan en las arquitecturas **x86**, **ARM** y **MIPS**, y cómo afectan el rendimiento.

### Modo Inmediato vs. Indirecto
En el modo de **direccionamiento inmediato**, el valor del operando está incrustado directamente en la instrucción, lo que permite un acceso rápido y eficiente. Por ejemplo, en ARM, este modo es común para operaciones aritméticas simples, donde se requiere velocidad en lugar de flexibilidad. 

```assembly
MOV R0, #10  ; Carga el valor inmediato 10 en el registro R0
```
En contraste, el modo de direccionamiento indirecto utiliza una dirección almacenada en un registro para acceder a la memoria, lo que añade flexibilidad a costa de un mayor tiempo de acceso. En la arquitectura x86, este modo es frecuente en operaciones complejas de acceso a memoria.

```assembly
MOV EAX, [EBX]  ; Carga en EAX el valor almacenado en la dirección apuntada por EBX
```

### Impacto en el Rendimiento
El uso de modos de direccionamiento como el indirecto, aunque más flexible, introduce una mayor latencia debido al acceso adicional a la memoria. En arquitecturas como x86, este impacto puede mitigarse parcialmente mediante el uso de cachés y técnicas de prefetching, pero sigue siendo un factor clave en el rendimiento general del sistema. En arquitecturas RISC como ARM o MIPS, se priorizan los modos de direccionamiento simples, lo que permite un acceso más rápido a los operandos y reduce la latencia del pipeline [@stallings_organization_2016].

La elección entre CISC y RISC, así como el diseño del formato de instrucciones y los modos de direccionamiento, afecta profundamente el rendimiento y la eficiencia de un procesador. Mientras que CISC ofrece flexibilidad y un repertorio de instrucciones amplio a costa de una mayor complejidad, RISC prioriza la simplicidad y la velocidad. A medida que las arquitecturas de procesadores evolucionan, se observa una convergencia de ambas filosofías, donde las arquitecturas modernas integran características de ambos enfoques para maximizar el rendimiento y la eficiencia energética. Estos conceptos son fundamentales para entender el estado actual del diseño de procesadores y su evolución futura.

###   Arquitectura x86
La arquitectura x86, una de las más influyentes y ampliamente utilizadas en el ámbito de las computadoras de escritorio y servidores, comenzó su desarrollo en 1978 con el lanzamiento del procesador Intel 8086, que introdujo una arquitectura de 16 bits. La arquitectura x86 evolucionó significativamente con el Intel 80386 en 1985, marcando el inicio de la era de 32 bits. En 2003, AMD lanzó la arquitectura AMD64, extendiendo x86 a 64 bits, lo que permitió un mayor acceso a la memoria y un mejor rendimiento en aplicaciones intensivas. Intel adoptó estas innovaciones, consolidando la arquitectura x86 como una de las más versátiles y potentes del mercado [@intel_64_2016][@amd_developer_2019][@abel_ibm_2000].

####   Contextualización Histórica y Evolución de la Arquitectura x86
La retrocompatibilidad de la arquitectura x86 ha sido un factor determinante en su éxito, permitiendo que aplicaciones de 16, 32 y 64 bits se ejecuten en el mismo sistema. Esta característica ha asegurado la continuidad y protección de las inversiones en software y sistemas operativos desarrollados para x86.

```{r tabla-procesadores, echo=FALSE, message=FALSE, warning=FALSE}
library(knitr)

procesadores <- data.frame(
  Procesador = c("Intel 8086", "Intel 80386", "AMD64"),
  `Año de Lanzamiento` = c(1978, 1985, 2003),
  `Número de Bits` = c(16, 32, 64),
  `Nuevas Características` = c("Arquitectura inicial", "Memoria virtual", "Extensiones de 64 bits")
)

kable(procesadores, format = "markdown", caption = "Hitos procesadores x86")
```

La evolución de la arquitectura x86 ha estado marcada por hitos importantes que han impulsado la informática hacia nuevas alturas. Tras el Intel 8086, el lanzamiento del Intel 80286 en 1982 introdujo modos de operación adicionales que mejoraron la eficiencia y el manejo de memoria. En 1989, el Intel 80486 incorporó una unidad de punto flotante integrada y una mejor caché, aumentando significativamente el rendimiento.

La serie Pentium, iniciada en 1993, llevó la arquitectura x86 a nuevos niveles de rendimiento y eficiencia, con características avanzadas como la ejecución superescalar y la predicción de saltos. El Pentium Pro en 1995 mejoró la arquitectura con ejecución fuera de orden y una caché L2 integrada.

En la década de 2000, la arquitectura x86 se adaptó a las demandas de la computación moderna con la introducción del Intel Core, optimizando el rendimiento y la eficiencia energética. AMD también fue crucial con su serie Athlon y la introducción de AMD64, llevando la arquitectura x86 a 64 bits, permitiendo un mayor acceso a la memoria y mejorando el rendimiento en aplicaciones intensivas.

La arquitectura x86 ha tenido un impacto profundo en el desarrollo de software. Los sistemas operativos populares como Windows y Linux están optimizados para x86, lo que ha influido en el desarrollo y la optimización de aplicaciones para esta arquitectura.
- Influencia en el Desarrollo de Software: Optimización del Rendimiento: Los desarrolladores de software han trabajado estrechamente con las características de la arquitectura x86 para optimizar el rendimiento de sus aplicaciones. Esto incluye el uso de instrucciones específicas de x86 y la optimización para cachés y pipelines.
- Compatibilidad y Soporte: La compatibilidad hacia atrás de x86 ha permitido la continuidad de aplicaciones y sistemas operativos, protegiendo las inversiones en software y facilitando las actualizaciones.
- Ecosistema de Desarrollo: Un amplio ecosistema de herramientas de desarrollo, bibliotecas y frameworks ha sido construido alrededor de la arquitectura x86, facilitando el desarrollo de aplicaciones de alto rendimiento y su depuración.

```{r tabla-evolucion-x86, echo=FALSE, message=FALSE, warning=FALSE}
library(knitr)

evolucion_x86 <- data.frame(
  Año = c(1978, 1982, 1985, 1989, 1993, 1995, 2003, 2006),
  Procesador = c("Intel 8086", "Intel 80286", "Intel 80386", "Intel 80486", "Intel Pentium", "Intel Pentium Pro", "AMD64", "Intel Core"), # nolint
  `Innovación_Principal`  = c(
    "Introducción de la arquitectura x86, 16 bits",
    "Modos de operación adicionales",
    "Arquitectura de 32 bits, memoria virtual",
    "Unidad de punto flotante integrada, mejor caché",
    "Ejecución superescalar, predicción de saltos",
    "Ejecución fuera de orden, caché L2 integrada",
    "Extensiones a 64 bits, mayor acceso a memoria",
    "Optimización de rendimiento y eficiencia energética"
  )
)

kable(evolucion_x86, format = "markdown", caption = "Línea de Tiempo de la Evolución de la Arquitectura x86")
```

###  Repertorio de instrucciones arquitectura x86
La arquitectura x86 es conocida por su complejidad y flexibilidad, características que se reflejan en su repertorio de instrucciones. Las instrucciones x86 pueden variar considerablemente en su longitud y estructura, lo que permite una gran diversidad de operaciones pero también añade una capa de complejidad en su decodificación y ejecución. Según Stallings [@stallings_computer_2013], el formato de las instrucciones en x86 incluye una variedad de campos que pueden estar presentes o no dependiendo del tipo de instrucción.

##### Estructura General de una Instrucción x86
Una instrucción en la arquitectura x86 puede constar de los siguientes componentes:


- Prefijos: Opcionalmente, una instrucción puede comenzar con uno o más bytes de prefijo, que modifican la operación de la instrucción principal. Por ejemplo, el prefijo 0x66 se utiliza para cambiar el tamaño del operando de 32 bits a 16 bits.

- Código de Operación (Opcode): El opcode indica la operación que debe realizarse. En x86, el opcode 0x89, por ejemplo, representa la instrucción MOV para mover datos entre registros o entre un registro y la memoria.

- Modificadores de Dirección (ModR/M y SIB): Estos campos se utilizan para especificar los registros y/o direcciones de memoria involucrados en la instrucción. Por ejemplo, un byte ModR/M con un valor de 0xC1 podría indicar que el registro ECX debe ser utilizado en la operación.

- Desplazamiento y/o Inmediato: Dependiendo de la instrucción, puede incluir un valor de desplazamiento para direccionamiento indirecto o un valor inmediato que se utiliza como operando directo en la instrucción. Por ejemplo, un valor de desplazamiento de 0x10 podría indicar un desplazamiento de 16 bytes desde la dirección base.

##### Complejidad en la Decodificación
Una de las características distintivas del repertorio x86 es la variabilidad en la longitud de las instrucciones, que puede ir desde 1 byte hasta 15 bytes. Esta variabilidad incrementa significativamente la complejidad de la decodificación, ya que el procesador debe ser capaz de interpretar correctamente la longitud y los componentes de cada instrucción antes de su ejecución. En los procesadores x86 modernos, se han implementado técnicas avanzadas como la decodificación anticipada (pre-decoding) y el uso de microcódigos para manejar esta complejidad. Estas técnicas permiten que el procesador convierta instrucciones complejas de múltiples bytes en microinstrucciones más simples y eficientes que pueden ser ejecutadas en paralelo, mejorando así el rendimiento general del sistema.

Además, la inclusión de diferentes modos de direccionamiento y la posibilidad de emplear prefijos adicionales añade un nivel de dificultad en la interpretación de cada instrucción. Esto contrasta con arquitecturas más simples, donde las instrucciones tienen un formato fijo y una longitud constante.

Ejemplo de Instrucción x86
Una instrucción simple en x86 podría ser:

MOV AX, [BX+SI+16]

En este caso, el opcode MOV se traduce a un byte específico, y el uso de registros y desplazamientos se codifica mediante el byte ModR/M y el posible uso de un byte SIB. Este ejemplo ilustra cómo la instrucción compacta se expande a múltiples bytes en la memoria, y cómo la CPU debe descomponer estos bytes para ejecutar la operación correctamente.


## Lenguaje ensamblador
Un procesador puede interpretar y ejecutar solo instrucciones máquina. Estas instrucciones son simplemente secuencias de números binarios almacenados en la computadora y son leídas por el procesador e interpretadas por él. Si un programador quisiera programar directamente en el lenguaje máquina, necesita introducir los programas como datos binarios. Esto requeriría escribir las sentencias que necesita realizar el procesador directamente en binarios, por lo tanto, conocer la secuencia de ceros y unos para cada operación escribiéndose ordenadamente, además de respetar la estructura de memoria y direccionamientos del procesador. Esto sin duda es un trabajo complejo, difícil, pesado y muy susceptible a errores. Adicionalmente, una vez que se requiera realizar modificaciones, su lectura implica ir traduciendo estas secuencias de ceros y unos a su correspondiente instrucción, lo que es doblemente dificultoso [@irvine2011assembly]. 

Para facilitar la programación de bajo nivel, se creó el lenguaje ensamblador, que es un lenguaje de programación de bajo nivel que permite a los programadores escribir instrucciones comprensibles por el procesador. A diferencia del lenguaje máquina, que utiliza secuencias de números binarios, el ensamblador emplea mnemónicos simbólicos que hacen que el código sea más legible y manejable para los humanos. Cada arquitectura de procesador tiene su propio lenguaje ensamblador que usualmente es definida por el fabricante de hardware, por lo tanto es específica de cierta arquitectura de la computadora física. Un programa llamado ensamblador es usado para traducir sentencias del lenguaje ensamblador al código de máquina de la computadora. El ensamblador realiza una traducción casi directa uno a uno desde las sentencias mnemónicas a las instrucciones y datos de máquina. Esto está en contraste con los lenguajes de alto nivel, en los cuales una sola declaración generalmente da lugar a muchas instrucciones de máquina [@stallings_computer_2013]. 

El código fuente generado en mnemotécnicos debe ser traducido a lenguaje máquina para poder ser ejecutado por la computadora. Este proceso lo realizan programas denominados ensambladores. Dentro del contexto de la arquitectura x86, existen diversos lenguajes ensambladores como TASM (Turbo Assembler) [@tasm], MASM (Microsoft Macro Assembler) [@masm] y NASM (Netwide Assembler) [@nasm], cada uno con características y beneficios únicos que se adaptan a distintas necesidades y preferencias de los programadores. Estos ensambladores convierten el código simbólico en código máquina, permitiendo su ejecución en el hardware específico de la arquitectura x86 [@hyde2010art].

##  Simulación
La simulación es una herramienta esencial en diversos campos, incluyendo la medicina, el ámbito militar, el entretenimiento y la educación.Facilita la comprensión del funcionamiento de sistemas, la generación de hipótesis, la realización de análisis predictivos y la respuesta a preguntas del tipo "¿qué pasaría si?".

Según Banks [@banks_discrete-event_2010], la simulación se define como el proceso de imitar el comportamiento de un sistema a lo largo del tiempo, lo cual requiere desarrollar primero un modelo conceptual que capture las características y comportamientos del sistema real. La simulación, entonces, representa la evolución de este modelo conforme el tiempo avanza [@banks_discrete-event_2010][@robinson_simulation_2014].

La capacidad de replicar y analizar sistemas complejos sin intervenir directamente en ellos convierte la simulación en una metodología indispensable para ingenieros, diseñadores y gerentes en el mundo digital actual. La simulación permite evaluar el rendimiento de sistemas, predecir su comportamiento en diferentes escenarios y optimizar su diseño antes de implementarlos en la realidad. Con los avances en el mundo digital, la simulación se ha convertido en una metodología indispensable para ingenieros, docentes, diseñadores y gerentes. La complejidad intrínseca de los sistemas informáticos los hace difíciles de comprender y costosos de desarrollar sin utilizar simulación. [@law_simulation_2015].

###  Aplicaciones de la Simulación en la Industria
En la industria automotriz, la simulación es fundamental para el diseño y prueba de sistemas de seguridad, como airbags y frenos. Mediante un modelo virtual del automóvil y sus componentes, es posible realizar pruebas de colisión y evaluar el rendimiento de los sistemas de seguridad sin recurrir a costosas pruebas físicas. Además, la simulación permite optimizar el diseño de motores, analizar el flujo aerodinámico y prever el comportamiento de los materiales en condiciones extremas. En el campo de la aviación, la simulación se utiliza para entrenar pilotos en simuladores de vuelo que replican condiciones reales sin riesgos. También se emplea en el diseño de aeronaves para evaluar la aerodinámica y el rendimiento de nuevos diseños bajo diversas condiciones de vuelo. Estos ejemplos ilustran cómo la simulación puede reducir costos, mejorar la seguridad y acelerar el desarrollo de productos complejos.

###  Simulación en la Educación
En el ámbito educativo, la simulación es una herramienta poderosa para enseñar conceptos complejos y fomentar el aprendizaje activo. Los simuladores permiten a los estudiantes interactuar con sistemas virtuales y experimentar con escenarios realistas, facilitando la comprensión de conceptos abstractos y la aplicación de conocimientos teóricos en situaciones prácticas. 

En la enseñanza de la arquitectura de computadoras, los simuladores son especialmente útiles para ilustrar el funcionamiento interno de los procesadores, la ejecución de instrucciones y el manejo de la memoria. Los estudiantes pueden experimentar con diferentes configuraciones y parámetros, observar el impacto en el rendimiento y comprender cómo se aplican los conceptos teóricos en la práctica. La simulación también permite a los estudiantes explorar escenarios hipotéticos y evaluar el comportamiento de sistemas complejos sin necesidad de hardware físico. En resumen, la simulación en la educación es una herramienta valiosa para mejorar la comprensión de los estudiantes, fomentar la experimentación y promover el aprendizaje activo [@skrien_cpu_2001][@garcia-garcia_pbbcache_2020][@nova_tool_2013].

Para superar estas limitaciones, se han desarrollado numerosos simuladores que ofrecen experiencias de aprendizaje valiosas al replicar el funcionamiento y la estructura de las computadoras. Simuladores como SimpleScalar, SPIM y GEM5 permiten a los estudiantes experimentar con arquitecturas complejas y técnicas avanzadas como el pipelining y la ejecución fuera de orden. Estas herramientas facilitan la comprensión de los conceptos teóricos a través de la interacción práctica, proporcionando un entorno seguro y accesible para la exploración y el aprendizaje [@skrien_cpu_2001].

Utilizando simuladores como SimpleScalar, los estudiantes pueden visualizar cómo las instrucciones se ejecutan en diferentes etapas del pipeline, y cómo se manejan las dependencias de datos y los riesgos de control. El pipelining es una técnica utilizada en las CPUs modernas para mejorar el rendimiento. Al simular el pipelining, los estudiantes pueden comprender cómo se dividen las instrucciones en etapas y cómo se gestionan los conflictos para evitar cuellos de botella. Además, los simuladores permiten a los estudiantes experimentar con diferentes configuraciones y parámetros para evaluar su impacto en el rendimiento y la eficiencia de la CPU.

#### Aporte pedagógico
En el ámbito educativo, transmitir los fundamentos teóricos de la organización y arquitectura interna de las computadoras puede ser un desafío debido a la complejidad de los procesos involucrados. Los métodos tradicionales de enseñanza, como el uso de pizarras, libros de texto y diapositivas, a menudo tienen una capacidad limitada para representar estos conceptos de manera efectiva. Esto requiere que los estudiantes tengan un alto nivel de abstracción para desarrollar un modelo mental adecuado para capturar la organización y arquitectura interna de las computadoras [@lion_simuladores_2005][@contreras_uso_2010].

La integración de nuevas tecnologías como recurso didáctico es crucial para facilitar el aprendizaje. Las herramientas de simulación permiten a los estudiantes relacionar conceptos abstractos con situaciones reales, situándose en un contexto que imita aspectos de la realidad. Este enfoque pedagógico facilita la detección de problemáticas y el desarrollo de habilidades a través del trabajo exploratorio, la inferencia y el aprendizaje por descubrimiento. Simuladores como Simulink, Proteus y Logisim juegan un papel esencial en la enseñanza de la arquitectura de computadoras, proporcionando una representación visual e interactiva que enriquece la comprensión teórica y práctica de los estudiantes [@garcia-garcia_pbbcache_2020][@nova_tool_2013].

El uso de herramientas de simulación en la enseñanza para procesos dinámicos complejos, como las operaciones intrínsecas de la computadora, que permiten representar de forma visual e interactiva la organización y arquitectura interna de la computadora, facilitando así la comprensión de su funcionamiento por parte de los alumnos y el desarrollo de los temas por parte del docente. En este contexto, los simuladores juegan una pieza clave en el campo de la Arquitectura de Computadoras, permitiendo conectar fundamentos teóricos con la experiencia práctica, implicando abstracciones y haciendo más rica la labor docente.

### El Formalismo DEVS (Discrete Event System Specification)
DEVS, la abreviación de Discrete Event System Specification, es un formalismo modular y jerárquico para el modelado y análisis de sistemas que pueden ser representados como sistemas de eventos discretos, sistemas de estado continuo o sistemas híbridos. Este formalismo, desarrollado por Bernard P. Zeigler en los años 70, extiende el concepto de las máquinas de Moore al proporcionar una estructura para modelar sistemas complejos mediante la utilización de eventos cronometrados [@zeigler_theory_2000].

#### Descripción del Formalismo DEVS
El formalismo DEVS define el comportamiento de un sistema real utilizando eventos de entrada y salida, y transiciones entre estados concretos. Un sistema en DEVS está compuesto por modelos atómicos y acoplados. Los modelos atómicos representan las unidades básicas de comportamiento, mientras que los modelos acoplados consisten en combinaciones de modelos atómicos y/o otros modelos acoplados. Esta estructura jerárquica facilita la gestión y análisis de sistemas complejos, permitiendo la prueba de subsistemas de manera aislada antes de integrarlos en el sistema completo.
Bajo un punto de vista general, un modelo DEVS está caracterizado por generar eventos de salida Y , en relación con el estado en el que se encuentre S y las entradas recibidas X, cada cierto tiempo.

#### Aplicaciones del Formalismo DEVS
El formalismo DEVS es aplicable a una amplia gama de sistemas, desde redes de comunicación hasta procesos de manufactura. Por ejemplo, en una red de comunicación, un modelo DEVS puede simular el enrutamiento de paquetes de datos y la gestión de congestiones. En la manufactura, un modelo DEVS puede representar el flujo de materiales y el control de calidad en una línea de producción, ayudando a identificar cuellos de botella y optimizar procesos.
